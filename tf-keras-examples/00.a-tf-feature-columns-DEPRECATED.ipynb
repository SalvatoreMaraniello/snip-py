{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAMjDIla4NgF"
      },
      "source": [
        "# Feature Columns with tf.feature_column - DEPRECATED\n",
        "\n",
        "> Important: `tf.feature_column` has been deprecate. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
        "\n",
        "This tutorial details feature columns. Think of feature columns as the intermediaries between raw data and Estimators. Feature columns are very rich, enabling you to transform a diverse range of raw data into formats that Estimators can use, allowing easy experimentation.\n",
        "\n",
        "*In simple words feature column are bridge between raw data and estimator or model.*\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/feature_columns/feature_cloud.jpg)\n",
        "Some real-world features (such as, longitude) are numerical, but many are not.\n",
        "\n",
        "Input to a Deep Neural Network\n",
        "\n",
        "What kind of data can a deep neural network operate on? The answer is, of course, numbers (for example, tf.float32). After all, every neuron in a neural network performs multiplication and addition operations on weights and input data. Real-life input data, however, often contains non-numerical (categorical) data. For example, consider a product_class feature that can contain the following three non-numerical values:\n",
        "\n",
        "*  kitchenware\n",
        "* electronics\n",
        "* sports\n",
        "\n",
        "ML models generally represent categorical values as simple vectors in which a 1 represents the presence of a value and a 0 represents the absence of a value. For example, when product_class is set to sports, an ML model would usually represent product_class as [0, 0, 1], meaning:\n",
        "\n",
        " * 0: kitchenware is absent\n",
        " *  0: electronics is absent\n",
        " *  1: sports is present\n",
        "\n",
        "So, although raw data can be numerical or categorical, an ML model represents all features as numbers.\n",
        "\n",
        "## Feature Columns\n",
        "\n",
        "As the following figure suggests, you specify the input to a model through the feature_columns argument of an Estimator (DNNClassifier for Iris). Feature Columns bridge input data (as returned by input_fn) with your model.\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/feature_columns/inputs_to_model_bridge.jpg)\n",
        "\n",
        "   Feature columns bridge raw data with the data your model needs.\n",
        "   \n",
        "   To create feature columns, call functions from the tf.feature_column module. This tutorial explains nine of the functions in that module. As the following figure shows, all nine functions return either a Categorical-Column or a Dense-Column object, except bucketized_column, which inherits from both classes:\n",
        "   \n",
        "   ![alt text](https://www.tensorflow.org/images/feature_columns/some_constructors.jpg)\n",
        "   Feature column methods fall into two main categories and one hybrid category.\n",
        "   \n",
        "   Let's look at these functions in more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsJ3PtckG0t4"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Cl0qfVS4BiI"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu5Gg8k5KCL4"
      },
      "source": [
        "## Create Demo data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4gvmkgxxA66_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marks</th>\n",
              "      <th>marks_float</th>\n",
              "      <th>grade</th>\n",
              "      <th>point</th>\n",
              "      <th>pass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55</td>\n",
              "      <td>55.400</td>\n",
              "      <td>average</td>\n",
              "      <td>c</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>21.400</td>\n",
              "      <td>poor</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>63.000</td>\n",
              "      <td>average</td>\n",
              "      <td>c+</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>88</td>\n",
              "      <td>88.000</td>\n",
              "      <td>good</td>\n",
              "      <td>b+</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74</td>\n",
              "      <td>74.999</td>\n",
              "      <td>good</td>\n",
              "      <td>b</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>54</td>\n",
              "      <td>54.000</td>\n",
              "      <td>average</td>\n",
              "      <td>c</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>95</td>\n",
              "      <td>95.000</td>\n",
              "      <td>good</td>\n",
              "      <td>a</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>41</td>\n",
              "      <td>41.000</td>\n",
              "      <td>average</td>\n",
              "      <td>d+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>84</td>\n",
              "      <td>84.000</td>\n",
              "      <td>good</td>\n",
              "      <td>b+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>52</td>\n",
              "      <td>52.000</td>\n",
              "      <td>average</td>\n",
              "      <td>c</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   marks  marks_float    grade point  pass\n",
              "0     55       55.400  average     c     0\n",
              "1     21       21.400     poor     f     0\n",
              "2     63       63.000  average    c+     1\n",
              "3     88       88.000     good    b+     1\n",
              "4     74       74.999     good     b     1\n",
              "5     54       54.000  average     c     1\n",
              "6     95       95.000     good     a     0\n",
              "7     41       41.000  average    d+     0\n",
              "8     84       84.000     good    b+     0\n",
              "9     52       52.000  average     c     0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = {'marks': [55,21,63,88,74,54,95,41,84,52],\n",
        "        'marks_float': [55.4,21.4,63,88,74.999,54,95,41,84,52],\n",
        "        'grade': ['average','poor','average','good','good','average','good','average','good','average'],\n",
        "        'point': ['c','f','c+','b+','b','c','a','d+','b+','c'],\n",
        "        'pass': [0,0,1,1,1,1,0,0,0,0],\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "saya2UL2E5An",
        "outputId": "a1ffe32c-d30d-4a1a-c178-b9dd563ae96e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "marks            int64\n",
              "marks_float    float64\n",
              "grade           object\n",
              "point           object\n",
              "pass             int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w5rgPy7VSYQ"
      },
      "source": [
        "## Demonstrate several types of feature column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTloL_wkWDhO"
      },
      "source": [
        "### Numeric columns\n",
        "The output of a feature column becomes the input to the model (using the demo function defined above, we will be able to see exactly how each column from the dataframe is transformed). A [numeric column](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column) is the simplest type of column. It is used to represent real valued features. When using this column, your model will receive the column value from the dataframe unchanged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "qfmjwJm_Ci3M",
        "outputId": "5ffd0b0a-1dde-42ec-9a45-76f379361381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /var/folders/9y/sqc9kmdx5zd6qxhv8ry35jqw0000gp/T/ipykernel_48173/2268056259.py:2: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NumericColumn(key='marks', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# deprecated approach\n",
        "marks = feature_column.numeric_column(\"marks\")\n",
        "marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R6Azy4ElGOr"
      },
      "source": [
        "### Bucketized columns\n",
        "Often, you don't want to feed a number directly into the model, but instead split its value into different categories based on numerical ranges. Consider raw data that represents a person's age. Instead of representing age as a numeric column, we could split the age into several buckets using a [bucketized column](https://www.tensorflow.org/api_docs/python/tf/feature_column/bucketized_column). Notice the one-hot values below describe which age range each row matches.\n",
        "     Buckets include the left boundary, and exclude the right boundary.\n",
        " For example, consider raw data that represents the year a house was built. Instead of representing that year as a scalar numeric column, we could split the year into buckets\n",
        "\n",
        "The model will represent the buckets as follows:\n",
        "Date Range| Description|\n",
        "------------|--------------------\n",
        "< 1960 |  \t[1, 0, 0, 0]|\n",
        "$\\ge$ 1960 but < 1980 | [0, 1, 0, 0]|\n",
        "$\\ge$ 1980 but < 2000 | [0, 0, 1, 0]|\n",
        "$\\ge$ 2000| [0, 0, 0, 1] |\n",
        "\n",
        "Why would you want to split a number—a perfectly valid input to your model—into a categorical value? Well, notice that the categorization splits a single input number into a four-element vector. Therefore, the model now can learn four individual weights rather than just one; four weights creates a richer model than one weight. More importantly, bucketizing enables the model to clearly distinguish between different year categories since only one of the elements is set (1) and the other three elements are cleared (0). For example, when we just use a single number (a year) as input, a linear model can only learn a linear relationship. So, bucketing provides the model with additional flexibility that the model can use to learn.\n",
        "\n",
        "The following code demonstrates how to create a bucketized feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "EZwwpcSNSguF",
        "outputId": "70778964-9cc0-404e-c2b0-aa1622343be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /var/folders/9y/sqc9kmdx5zd6qxhv8ry35jqw0000gp/T/ipykernel_48173/3185480129.py:2: bucketized_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BucketizedColumn(source_column=NumericColumn(key='marks', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(30, 40, 50, 60, 70, 80, 90))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# deprecated approach\n",
        "marks_buckets = feature_column.bucketized_column(marks, boundaries=[30,40,50,60,70,80,90])\n",
        "marks_buckets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DE8jgeury8i"
      },
      "source": [
        "## Categorical Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zduHmN7arYe3"
      },
      "source": [
        "## Indicator and embedding columns\n",
        "Indicator columns and embedding columns never work on features directly, but instead take categorical columns as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOJN5DBcouRC"
      },
      "source": [
        "### Indicator columns (i.e. One-Hot encoding)\n",
        "The categorical vocabulary columns provide a way to represent strings as a one-hot vector (much like you have seen above with age buckets). \n",
        "\n",
        "The vocabulary can be passed as a list using [categorical_column_with_vocabulary_list](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list), or loaded from a file using [categorical_column_with_vocabulary_file](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "Jf_mIYwBVXkh",
        "outputId": "5773b4dc-068e-41fd-de75-8e998593a249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /var/folders/9y/sqc9kmdx5zd6qxhv8ry35jqw0000gp/T/ipykernel_48173/2957831512.py:2: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From /var/folders/9y/sqc9kmdx5zd6qxhv8ry35jqw0000gp/T/ipykernel_48173/2957831512.py:3: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='grade', vocabulary_list=('poor', 'average', 'good'), dtype=tf.string, default_value=-1, num_oov_buckets=0))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary = ['poor', 'average', 'good'] # i.e., admitted categories\n",
        "grade = feature_column.categorical_column_with_vocabulary_list('grade', vocabulary)\n",
        "grade_one_hot = feature_column.indicator_column(grade)\n",
        "grade_one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maOiPeuVqaWw"
      },
      "source": [
        "### Embedding columns\n",
        "\n",
        "As the number of categories grow large, it becomes infeasible to train a neural network using one-hot encodings. Instead of representing the data as a one-hot vector of many dimensions, $N_c$, represents that data as a lower-dimensional, $N_d \\ll N_c$, dense vector in which each cell can contain any number, not just 0 or 1. The size of the embedding (8, in the example below) is a parameter that must be tuned.\n",
        "\n",
        "Key point: using an embedding column is best when a categorical column has many possible values. We are using one here for demonstration purposes, so you have a complete example you can modify for a different dataset in the future.\n",
        "\n",
        "> Note: when building embeddingm you start from $x_e = W_e \\cdot x_o$, where $x_e$ and $x_o$ are the embedded and one-hot encoded representation of a given category, and train the coefficients of a $W_e$ a dense float matrix of size $N_d \\times N_c$. If you write $W=[w_1, w_2, ..., w_{N_c}] $ You will see that the embedding on the i-th category is nothing but $w_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv20a--3sN8f"
      },
      "source": [
        "### Point column as embedding_column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "U0rppLoAYS8h",
        "outputId": "9cf4b132-228f-4613-b507-8289a664d4a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabulary=array(['c', 'f', 'c+', 'b+', 'b', 'a', 'd+'], dtype=object)\n",
            "WARNING:tensorflow:From /var/folders/9y/sqc9kmdx5zd6qxhv8ry35jqw0000gp/T/ipykernel_48173/3384660717.py:6: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='point', vocabulary_list=('c', 'f', 'c+', 'b+', 'b', 'a', 'd+'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1616631d0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# deprecated approach\n",
        "vocabulary = df['point'].unique()\n",
        "print(f'{vocabulary=}')\n",
        "\n",
        "point = feature_column.categorical_column_with_vocabulary_list('point', vocabulary) # this syntax is the same as for 1-hot encoding\n",
        "point_embedding = feature_column.embedding_column(point, dimension=4)\n",
        "point_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k-SekdXu6M6"
      },
      "source": [
        "### Hashed feature columns\n",
        "\n",
        "Another way to represent a categorical column with a large number of values is to use a [categorical_column_with_hash_bucket](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_hash_bucket). This feature column calculates a hash value of the input, then selects one of the `hash_bucket_size` buckets to encode a string. When using this column, you do not need to provide the vocabulary, and you can choose to make the number of hash_buckets significantly smaller than the number of actual categories to save space.\n",
        "\n",
        "Key point: An important downside of this technique is that there may be collisions in which different strings are mapped to the same bucket. In practice, this can work well for some datasets regardless."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "05OX5LKgb6O9",
        "outputId": "aa9615cb-e905-47a4-c536-87f49ffdcf7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /var/folders/9y/sqc9kmdx5zd6qxhv8ry35jqw0000gp/T/ipykernel_48173/2400986833.py:2: categorical_column_with_hash_bucket (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "IndicatorColumn(categorical_column=HashedCategoricalColumn(key='point', hash_bucket_size=4, dtype=tf.string))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# deprecated approach\n",
        "point_hashed = feature_column.categorical_column_with_hash_bucket(\n",
        "      'point', hash_bucket_size=4)\n",
        "feature_column.indicator_column(point_hashed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBSuelh0zjOS"
      },
      "source": [
        "At this point, you might rightfully think: \"This is crazy!\" After all, we are forcing the different input values to a smaller set of categories. This means that two probably unrelated inputs will be mapped to the same category, and consequently mean the same thing to the neural network. The following figure illustrates this dilemma, showing that kitchenware and sports both get assigned to category (hash bucket) 12:\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/feature_columns/hashed_column.jpg)\n",
        "Representing data with hash buckets.\n",
        "\n",
        "As with many counterintuitive phenomena in machine learning, it turns out that hashing often works well in practice. That's because hash categories provide the model with some separation. The model can use additional features to further separate kitchenware from sports."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6nW2Ffkzxjn"
      },
      "source": [
        "### Crossed feature columns\n",
        "Combining features into a single feature, better known as [feature crosses](https://developers.google.com/machine-learning/glossary/#feature_cross), enables a model to learn separate weights for each combination of features. Here, we will create a new feature that is the cross of marks and age. Note that `crossed_column` does not build the full table of all possible combinations (which could be very large). \n",
        "\n",
        "- Instead, it is backed by a `hashed_column`, so you can choose how large the table is. \n",
        "- This is not the only way. Say you have two embedding matrices, $W_a$ and $W_b$. If you just concatenate them, you can create a feature $x = x_a + x_b$ which is the sum of the emebedding vectors. You can feed this into a model (e.g. a linear model), such that $x = \\alpha x_a + \\beta x_b$, etc.\n",
        "\n",
        "In all the approaches, the net efect is that the model learns separate weights for each combination of features.\n",
        "\n",
        "More concretely, suppose we want our model to calculate real estate prices in Atlanta, GA. Real-estate prices within this city vary greatly depending on location. Representing latitude and longitude as separate features isn't very useful in identifying real-estate location dependencies; however, crossing latitude and longitude into a single feature can pinpoint locations. Suppose we represent Atlanta as a grid of 100x100 rectangular sections, identifying each of the 10,000 sections by a feature cross of latitude and longitude. This feature cross enables the model to train on pricing conditions related to each individual section, which is a much stronger signal than latitude and longitude alone.\n",
        "\n",
        "The following figure shows our plan, with the latitude & longitude values for the corners of the city in red text:\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/feature_columns/Atlanta.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "9WtVFBQTcWa0",
        "outputId": "fb396259-57ba-47f2-8e42-a0dc66a715e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /var/folders/9y/sqc9kmdx5zd6qxhv8ry35jqw0000gp/T/ipykernel_48173/2711836366.py:2: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "IndicatorColumn(categorical_column=CrossedColumn(keys=(BucketizedColumn(source_column=NumericColumn(key='marks', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(30, 40, 50, 60, 70, 80, 90)), VocabularyListCategoricalColumn(key='grade', vocabulary_list=('poor', 'average', 'good'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=10, hash_key=None))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# deprecated approach\n",
        "crossed_feature = feature_column.crossed_column([marks_buckets, grade], hash_bucket_size=10)\n",
        "feature_column.indicator_column(crossed_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3963qm9l2iXb"
      },
      "source": [
        "You may create a feature cross from either of the following:\n",
        "\n",
        "  * Feature names; that is, names from the dict returned from input_fn.\n",
        "  * Any categorical column, except categorical_column_with_hash_bucket (since crossed_column hashes the input).\n",
        "\n",
        "Except that a full grid would only be tractable for inputs with limited vocabularies. Instead of building this, potentially huge, table of inputs, the crossed_column only builds the number requested by the hash_bucket_size argument. The feature column assigns an example to a index by running a hash function on the tuple of inputs, followed by a modulo operation with hash_bucket_size.\n",
        "\n",
        "As discussed earlier, performing the hash and modulo function limits the number of categories, but can cause category collisions; that is, multiple (latitude, longitude) feature crosses will end up in the same hash bucket. In practice though, performing feature crosses still adds significant value to the learning capability of your models.\n",
        "\n",
        "Somewhat counterintuitively, when creating feature crosses, you typically still should include the original (uncrossed) features in your model (as in the preceding code snippet). The independent latitude and longitude features help the model distinguish between examples where a hash collision has occurred in the crossed feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function tensorflow.python.feature_column.feature_column_v2.crossed_column(keys, hash_bucket_size, hash_key=None)>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_column.crossed_column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
