{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cde16a5-2547-4d65-a1f1-5def515ff342",
   "metadata": {},
   "source": [
    "# Streaming Updates into Vertex AI Vector Search\n",
    "\n",
    "### Objectives\n",
    "Here, you will learn how to create Approximate Nearest Neighbor (ANN) Index, update index using stream update, and query against indexes.\n",
    "\n",
    "The steps performed in this lab include:\n",
    "\n",
    "-Create ANN Index\n",
    "-Create an IndexEndpoint with VPC Network\n",
    "-Deploy ANN Index\n",
    "-Perform online query\n",
    "-Update index by using stream udpate\n",
    "-Compute recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43346bbb-fecc-4fd2-a9d2-cd64149418cd",
   "metadata": {},
   "source": [
    "## Virtual Private Network Setup\n",
    "In this exercise, we use a VPN, instead of deploying the vector search endpoint publicly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a079f58f-3dfb-41fb-9272-366105e56b01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created [https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-00-3772106686f0/global/addresses/cym-range].\n",
      "Operation \"operations/pssn.p24-857821617613-e91564e4-ca84-4f14-b77e-9e1d4d735ff9\" finished successfully.\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-00-3772106686f0\"\n",
    "NETWORK_NAME = \"default\"\n",
    "PEERING_RANGE_NAME = \"cym-range\"\n",
    "\n",
    "# Reserve IP range\n",
    "! gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={NETWORK_NAME} --purpose=VPC_PEERING --project={PROJECT_ID} --description=\"peering range for cymbal demo\"\n",
    "\n",
    "# Set up peering with service networking\n",
    "! gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={NETWORK_NAME} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a06df6-6871-4a69-86d7-fdd3714e30ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/googleapis/python-aiplatform.git@main\n",
      "  Cloning https://github.com/googleapis/python-aiplatform.git (to revision main) to /var/tmp/pip-req-build-x7ajulb7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/googleapis/python-aiplatform.git /var/tmp/pip-req-build-x7ajulb7\n",
      "  Resolved https://github.com/googleapis/python-aiplatform.git to commit 91c8df52669f8072a60cc1555cba5c4d8c0d41c0\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.122.0) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (2.41.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (6.31.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (25.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (3.38.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (2.1.2)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (1.42.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (2.12.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (4.15.0)\n",
      "Requirement already satisfied: docstring_parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (0.17.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.122.0) (2.19.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.122.0) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.122.0) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.122.0) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.122.0) (1.75.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.122.0) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.122.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.122.0) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.122.0) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.122.0) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.122.0) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform==1.122.0) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform==1.122.0) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (4.11.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (1.3.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.122.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.122.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.122.0) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.122.0) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.122.0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.122.0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.122.0) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.122.0) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0->google-cloud-aiplatform==1.122.0) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting grpcio-tools\n",
      "  Downloading grpcio_tools-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=6.31.1 in /opt/conda/lib/python3.10/site-packages (from grpcio-tools) (6.31.1)\n",
      "Collecting grpcio>=1.76.0 (from grpcio-tools)\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from grpcio-tools) (80.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /opt/conda/lib/python3.10/site-packages (from grpcio>=1.76.0->grpcio-tools) (4.15.0)\n",
      "Downloading grpcio_tools-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: grpcio, grpcio-tools\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [grpcio]\u001b[33m  WARNING: The script python-grpc-tools-protoc is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [grpcio-tools]\n",
      "\u001b[1A\u001b[2KSuccessfully installed grpcio-1.76.0 grpcio-tools-1.76.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.15.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from h5py) (1.26.4)\n",
      "Downloading h5py-3.15.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h5py\n",
      "Successfully installed h5py-3.15.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting proto-plus==1.24.0.dev1\n",
      "  Downloading proto_plus-1.24.0.dev1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf<5.0.0dev,>=3.19.0 (from proto-plus==1.24.0.dev1)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Downloading proto_plus-1.24.0.dev1-py3-none-any.whl (49 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Installing collected packages: protobuf, proto-plus\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 6.31.1\n",
      "\u001b[2K    Uninstalling protobuf-6.31.1:\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.31.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~rotobuf'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: proto-plus\n",
      "\u001b[2K    Found existing installation: proto-plus 1.26.1[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling proto-plus-1.26.1:━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled proto-plus-1.26.1 \u001b[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [proto-plus]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~roto'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [proto-plus]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-tools 1.76.0 requires protobuf<7.0.0,>=6.31.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "grpcio-status 1.75.1 requires protobuf<7.0.0,>=6.31.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "kfp 2.14.4 requires protobuf<7.0,==6.31.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "kfp-pipeline-spec 2.14.0 requires protobuf<7.0,==6.31.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed proto-plus-1.24.0.dev1 protobuf-4.25.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -U git+https://github.com/googleapis/python-aiplatform.git@main --user\n",
    "\n",
    "# Install the h5py to prepare sample dataset, and the grpcio-tools for querying against the index.\n",
    "! pip install -U grpcio-tools --user\n",
    "! pip install -U h5py --user\n",
    "! pip install proto-plus==1.24.0.dev1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "855bac02-07df-4da4-85c2-c57b9fc97ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220b6ec-2308-48c7-a655-22f69b1ea6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b69a4a2c-325a-4e11-a6d8-e1051470d655",
   "metadata": {},
   "source": [
    "## Create a Cloud Storage bucket\n",
    "This will store the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dede44ed-b8c9-472f-b62a-47aa4956f99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-00-3772106686f0-aip/...\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"gs://qwiklabs-gcp-00-3772106686f0-aip\"\n",
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = \"qwiklabs-gcp-00-3772106686f0\"\n",
    "NETWORK_NAME = \"default\"\n",
    "\n",
    "\n",
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_NAME\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284525e9-ad39-4554-bb06-4932203f804f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validate access.\n",
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c19162-2ef6-4f95-93ea-72f2262caf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b913300-fdcd-4d9c-9e7a-5e8b01077aaf",
   "metadata": {},
   "source": [
    "## Setup Vertex AI \n",
    "\n",
    "**Note:** this being a demo, there is a lot of bad practice (e.g. import in the middle of the notebook, some variables, e.g. `REGION`,  being used for multiple purposes, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "329dc2d7-f31a-4b11-b308-c2f931898d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (4.25.8)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.8\n",
      "    Uninstalling protobuf-4.25.8:\n",
      "      Successfully uninstalled protobuf-4.25.8\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.14.4 requires protobuf<7.0,==6.31.1, but you have protobuf 6.33.0 which is incompatible.\n",
      "kfp-pipeline-spec 2.14.0 requires protobuf<7.0,==6.31.1, but you have protobuf 6.33.0 which is incompatible.\n",
      "proto-plus 1.24.0.dev1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-6.33.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Upgrade protobuf to the latest version\n",
    "!pip install --upgrade protobuf\n",
    "\n",
    "import time\n",
    "import grpc\n",
    "import h5py\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.protobuf import struct_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89add870-321d-4566-8d91-152f5f45a77e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT: us-central1-aiplatform.googleapis.com\n",
      "PROJECT_ID: qwiklabs-gcp-00-3772106686f0\n",
      "REGION: us-central1\n",
      "Updated property [core/project].\n",
      "Updated property [ai_platform/region].\n"
     ]
    }
   ],
   "source": [
    "REGION = \"us-central1\"\n",
    "ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "NETWORK_NAME = \"default\"\n",
    "\n",
    "AUTH_TOKEN = !gcloud auth print-access-token\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, REGION)\n",
    "\n",
    "print(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "print(\"PROJECT_ID: {}\".format(PROJECT_ID))\n",
    "print(\"REGION: {}\".format(REGION))\n",
    "\n",
    "!gcloud config set project {PROJECT_ID} --quiet\n",
    "!gcloud config set ai_platform/region {REGION} --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa6095-ae1d-487a-b11c-1058bd946b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "341d124a-0ad4-439e-9d14-7af7d3743d62",
   "metadata": {},
   "source": [
    "## Prepare Dummy Data\n",
    "We use the GloVe dataset as a demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522cb26f-c87a-4fed-a706-c09be703fa89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/vertex-ai/matching_engine/glove-100-angular.hdf5...\n",
      "\\ [1 files][462.9 MiB/462.9 MiB]   38.4 MiB/s                                   \n",
      "Operation completed over 1 objects/462.9 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://cloud-samples-data/vertex-ai/matching_engine/glove-100-angular.hdf5 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf98da5-118d-4951-8718-228b464af1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each embeddings has shape (100,)\n"
     ]
    }
   ],
   "source": [
    "# Read the data in memory\n",
    "h5 = h5py.File(\"glove-100-angular.hdf5\", \"r\")\n",
    "train = h5[\"train\"]\n",
    "test = h5[\"test\"]\n",
    "\n",
    "print(f'Each embeddings has shape {train[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87894ea0-ed89-4378-97c6-1c116d94ea81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Same train/test split in JSONL.\n",
    "\n",
    "# Add restricts to each data point, in this demo, we only add one namespace and the allowlist is set to be the same as the id.\n",
    "# Later on, we will demo how to return only the allowlisted data points.\n",
    "# Split datapoins into two groups 'a' and 'b'. The datapoint whose ids are even are in group 'a', otherwise are in group 'b'\n",
    "# We will demo how to configure the query to return up to k data points for each group.\n",
    "with open(\"glove100.json\", \"w\") as f:\n",
    "    for i in range(len(train)):\n",
    "        f.write('{\"id\":\"' + str(i) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in train[i]) + \"],\")\n",
    "        f.write('\"restricts\":[{\"namespace\": \"class\", \"allow\": [\"' + str(i) + '\"]}],')\n",
    "        f.write('\"crowding_tag\":' + ('\"a\"' if i % 2 == 0 else '\"b\"') + \"}\")\n",
    "        f.write(\"\\n\")\n",
    "        if i >= 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9237f9e-288b-499c-99cf-e3fd95da4750",
   "metadata": {},
   "source": [
    "```jsonl\n",
    "# Each element of this JSONL file is\n",
    "\n",
    "{\"id\":\"0\",\"embedding\":[-0.11333,0.48402,0.090771,-0.22439,0.034206,-0.55831,0.041849,-0.53573,0.18809,-0.58722,0.015313,-0.014555,0.80842,-0.038519,0.75348,0.70502,-0.17863,0.3222,0.67575,0.67198,0.26044,0.4187,-0.34122,0.2286,-0.53529,1.2582,-0.091543,0.19716,-0.037454,-0.3336,0.31399,0.36488,0.71263,0.1307,-0.24654,-0.52445,-0.036091,0.55068,0.10017,0.48095,0.71104,-0.053462,0.22325,0.30917,-0.39926,0.036634,-0.35431,-0.42795,0.46444,0.25586,0.68257,-0.20821,0.38433,0.055773,-0.2539,-0.20804,0.52522,-0.11399,-0.3253,-0.44104,0.17528,0.62255,0.50237,-0.7607,-0.071786,0.0080131,-0.13286,0.50097,0.18824,-0.54722,-0.42664,0.4292,0.14877,-0.0072514,-0.16484,-0.059798,0.9895,-0.61738,0.054169,0.48424,-0.35084,-0.27053,0.37829,0.11503,-0.39613,0.24266,0.39147,-0.075256,0.65093,-0.20822,-0.17456,0.53571,-0.16537,0.13582,-0.56016,0.016964,0.1277,0.94071,-0.22608,-0.021106],\"restricts\":[{\"namespace\": \"class\", \"allow\": [\"0\"]}],\"crowding_tag\":\"a\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca79dfa-41c8-4689-adc7-9b5c6a7d18bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying file://glove100.json [Content-Type=application/json]...\n",
      "/ [1 files][ 93.1 KiB/ 93.1 KiB]                                                \n",
      "Operation completed over 1 objects/93.1 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "### Upload the training data into GCS\n",
    "\n",
    "# NOTE: Everything in this GCS DIR will be DELETED before uploading the data.\n",
    "! gsutil rm -rf {BUCKET_NAME}/*\n",
    "\n",
    "! gsutil cp glove100.json {BUCKET_NAME}/glove100.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7af0e8-a0c2-4dfd-bad3-e46ddd0cd872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-00-3772106686f0-aip/glove100.json\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls {BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b4df2-4ff0-430e-9343-f1f2d25a7b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c43470b-5e9a-4b8d-964a-873ccc3841c6",
   "metadata": {},
   "source": [
    "## Create Stream Update Index\n",
    "Run the following code snippet in the next cells to create a instance of the IndexServiceClient from the AI Platform (Unified) Python client library. This is used for interacting with AI Platform services related to indexes, such as creating and managing Approximate Nearest Neighbor (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a69bf26-ed4a-4cbb-9bca-e8cf7755d910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_client = aiplatform_v1.IndexServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cdf1da5-8429-406d-9a27-d6cd74efb30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = 100\n",
    "DISPLAY_NAME = \"glove_100_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6f9f9-102f-4935-85ed-56355e5659b9",
   "metadata": {},
   "source": [
    "Let's define the configuration for creating an Approximate Nearest Neighbor (ANN) index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a85d7ff3-f31f-436b-ad41-218c622d1fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "treeAhConfig = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(number_value=500),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(number_value=7),\n",
    "    }\n",
    ")\n",
    "\n",
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"treeAhConfig\": struct_pb2.Value(struct_value=treeAhConfig)}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=BUCKET_NAME),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME,\n",
    "    \"description\": \"Glove 100 ANN index\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "    \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.STREAM_UPDATE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec14f47f-62eb-433f-bdf4-5185eb5d6c32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/857821617613/locations/us-central1/indexes/2460665241520832512\"\n",
       "display_name: \"glove_100_1\"\n",
       "description: \"Glove 100 ANN index\"\n",
       "metadata_schema_uri: \"gs://google-cloud-aiplatform/schema/matchingengine/metadata/nearest_neighbor_search_1.0.0.yaml\"\n",
       "metadata {\n",
       "  struct_value {\n",
       "    fields {\n",
       "      key: \"config\"\n",
       "      value {\n",
       "        struct_value {\n",
       "          fields {\n",
       "            key: \"shardSize\"\n",
       "            value {\n",
       "              string_value: \"SHARD_SIZE_MEDIUM\"\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"distanceMeasureType\"\n",
       "            value {\n",
       "              string_value: \"DOT_PRODUCT_DISTANCE\"\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"dimensions\"\n",
       "            value {\n",
       "              number_value: 100\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"approximateNeighborsCount\"\n",
       "            value {\n",
       "              number_value: 150\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"algorithmConfig\"\n",
       "            value {\n",
       "              struct_value {\n",
       "                fields {\n",
       "                  key: \"treeAhConfig\"\n",
       "                  value {\n",
       "                    struct_value {\n",
       "                      fields {\n",
       "                        key: \"leafNodesToSearchPercent\"\n",
       "                        value {\n",
       "                          number_value: 7\n",
       "                        }\n",
       "                      }\n",
       "                      fields {\n",
       "                        key: \"leafNodeEmbeddingCount\"\n",
       "                        value {\n",
       "                          string_value: \"500\"\n",
       "                        }\n",
       "                      }\n",
       "                    }\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "index_update_method: STREAM_UPDATE\n",
       "encryption_spec {\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's create an Approximate Nearest Neighbor (ANN) index using the specified configuration.\n",
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)\n",
    "# Retrieve the result of previously executed ann_index.\n",
    "ann_index.result()\n",
    "\n",
    "## Note: It can take up to 15 minutes to be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11015b9e-b259-4a8b-bb9e-3f63a1248228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/857821617613/locations/us-central1/indexes/2460665241520832512'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, retrieve the name of the created index (ann_index) and store it in the variable INDEX_RESOURCE_NAME.\n",
    "INDEX_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1169ff-3b04-4495-8880-b571e0a00c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09008b96-2235-4d67-97af-4e9615823f71",
   "metadata": {},
   "source": [
    "# Create an IndexEndpoint with VPC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7cf2e0b-5e08-4bce-86a6-188d3bc94f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the following code snippet to initialize an AI Platform Index Endpoint Service client.\n",
    "index_endpoint_client = aiplatform_v1.IndexEndpointServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a891d629-08a5-4097-941f-f1a2641350f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a configuration for an AI Platform Index Endpoint.\n",
    "VPC_NETWORK_NAME = f\"projects/{PROJECT_NUMBER}/global/networks/{NETWORK_NAME}\"\n",
    "\n",
    "index_endpoint = {\n",
    "    \"display_name\": \"index_endpoint_for_demo\",\n",
    "    \"network\": VPC_NETWORK_NAME,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eea1e80-2b2b-4585-9097-7d2fbc70ab39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/857821617613/locations/us-central1/indexEndpoints/5455602974187323392\"\n",
       "display_name: \"index_endpoint_for_demo\"\n",
       "network: \"projects/857821617613/global/networks/default\"\n",
       "encryption_spec {\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an AI Platform Index Endpoint.\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "    parent=PARENT, index_endpoint=index_endpoint\n",
    ")\n",
    "\n",
    "r.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b73f2dce-d9c6-4ce8-ba9b-ed106415484c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/857821617613/locations/us-central1/indexEndpoints/5455602974187323392'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = r.result().name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb0dff-3efe-4adc-9f2d-fc5693f43ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8111998e-d8d5-4d81-ac39-c80cbfff71c2",
   "metadata": {},
   "source": [
    "## Deploy Stream Update Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9e13848-d938-41ac-9566-de34227d3e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n"
     ]
    }
   ],
   "source": [
    "DEPLOYED_INDEX_ID = \"stream_update_glove_deployed\"\n",
    "\n",
    "deploy_ann_index = {\n",
    "    \"id\": DEPLOYED_INDEX_ID,\n",
    "    \"display_name\": DEPLOYED_INDEX_ID,\n",
    "    \"index\": INDEX_RESOURCE_NAME,\n",
    "}\n",
    "\n",
    "r = index_endpoint_client.deploy_index(\n",
    "    index_endpoint=INDEX_ENDPOINT_NAME, deployed_index=deploy_ann_index\n",
    ")\n",
    "\n",
    "# Poll the operation until it's done successfullly.\n",
    "while True:\n",
    "    if r.done():\n",
    "        break\n",
    "    print(\"Poll the operation to deploy index...\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2615fe-1878-4999-9327-e1f199dd6ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e34fb43b-acda-4b07-82a4-55f170a05f52",
   "metadata": {},
   "source": [
    "## Create Online Queries\n",
    "\n",
    "After you built your indexes, you may query against the deployed index through the online querying gRPC API (Match service) within the virtual machine instances from the same region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe614d-fced-490d-8f27-548ead9067ff",
   "metadata": {},
   "source": [
    "### Build a local MatchService\n",
    "\n",
    "The following code snippet to create write match_service.proto locally. This is a Protocol Buffer (protobuf) definition for a service called MatchService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b10dbe3d-66f0-47a2-a3ab-579dd65cb86c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing match_service.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile match_service.proto\n",
    "\n",
    "syntax = \"proto3\";\n",
    "\n",
    "package google.cloud.aiplatform.container.v1;\n",
    "\n",
    "// MatchService is a Google managed service for efficient vector similarity\n",
    "// search at scale.\n",
    "service MatchService {\n",
    "  // Returns the nearest neighbors for the query. If it is a sharded\n",
    "  // deployment, calls the other shards and aggregates the responses.\n",
    "  rpc Match(MatchRequest) returns (MatchResponse) {}\n",
    "}\n",
    "\n",
    "// Parameters for a match query.\n",
    "message MatchRequest {\n",
    "  // The ID of the DeploydIndex that will serve the request.\n",
    "  // This MatchRequest is sent to a specific IndexEndpoint of the Control API,\n",
    "  // as per the IndexEndpoint.network. That IndexEndpoint also has\n",
    "  // IndexEndpoint.deployed_indexes, and each such index has an\n",
    "  // DeployedIndex.id field.\n",
    "  // The value of the field below must equal one of the DeployedIndex.id\n",
    "  // fields of the IndexEndpoint that is being called for this request.\n",
    "  string deployed_index_id = 1;\n",
    "\n",
    "  // The embedding values.\n",
    "  repeated float float_val = 2;\n",
    "\n",
    "  // The number of nearest neighbors to be retrieved from database for\n",
    "  // each query. If not set, will use the default from\n",
    "  // the service configuration.\n",
    "  int32 num_neighbors = 3;\n",
    "\n",
    "  // The list of restricts.\n",
    "  repeated Namespace restricts = 4;\n",
    "\n",
    "  // Crowding is a constraint on a neighbor list produced by nearest neighbor\n",
    "  // search requiring that no more than some value k' of the k neighbors\n",
    "  // returned have the same value of crowding_attribute.\n",
    "  // It's used for improving result diversity.\n",
    "  // This field is the maximum number of matches with the same crowding tag.\n",
    "  int32 per_crowding_attribute_num_neighbors = 5;\n",
    "\n",
    "  // The number of neighbors to find via approximate search before\n",
    "  // exact reordering is performed. If not set, the default value from scam\n",
    "  // config is used; if set, this value must be > 0.\n",
    "  int32 approx_num_neighbors = 6;\n",
    "\n",
    "  // The fraction of the number of leaves to search, set at query time allows\n",
    "  // user to tune search performance. This value increase result in both search\n",
    "  // accuracy and latency increase. The value should be between 0.0 and 1.0. If\n",
    "  // not set or set to 0.0, query uses the default value specified in\n",
    "  // NearestNeighborSearchConfig.TreeAHConfig.leaf_nodes_to_search_percent.\n",
    "  int32 leaf_nodes_to_search_percent_override = 7;\n",
    "}\n",
    "\n",
    "// Response of a match query.\n",
    "message MatchResponse {\n",
    "  message Neighbor {\n",
    "    // The ids of the matches.\n",
    "    string id = 1;\n",
    "\n",
    "    // The distances of the matches.\n",
    "    double distance = 2;\n",
    "  }\n",
    "  // All its neighbors.\n",
    "  repeated Neighbor neighbor = 1;\n",
    "}\n",
    "\n",
    "// Namespace specifies the rules for determining the datapoints that are\n",
    "// eligible for each matching query, overall query is an AND across namespaces.\n",
    "message Namespace {\n",
    "  // The string name of the namespace that this proto is specifying,\n",
    "  // such as \"color\", \"shape\", \"geo\", or \"tags\".\n",
    "  string name = 1;\n",
    "\n",
    "  // The allowed tokens in the namespace.\n",
    "  repeated string allow_tokens = 2;\n",
    "\n",
    "  // The denied tokens in the namespace.\n",
    "  // The denied tokens have exactly the same format as the token fields, but\n",
    "  // represents a negation. When a token is denied, then matches will be\n",
    "  // excluded whenever the other datapoint has that token.\n",
    "  //\n",
    "  // For example, if a query specifies {color: red, blue, !purple}, then that\n",
    "  // query will match datapoints that are red or blue, but if those points are\n",
    "  // also purple, then they will be excluded even if they are red/blue.\n",
    "  repeated string deny_tokens = 3;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ca8d9eb-1053-40c2-a3c1-f79295f18c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'googleapis'...\n",
      "remote: Enumerating objects: 259509, done.\u001b[K\n",
      "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
      "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
      "remote: Total 259509 (delta 105), reused 58 (delta 54), pack-reused 259332 (from 3)\u001b[K\n",
      "Receiving objects: 100% (259509/259509), 230.30 MiB | 20.04 MiB/s, done.\n",
      "Resolving deltas: 100% (216479/216479), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository that contains the dependencies of match_service.proto.\n",
    "\n",
    "! git clone https://github.com/googleapis/googleapis.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa8bb1-2be9-4a0d-bdcc-1cd02435bb9d",
   "metadata": {},
   "source": [
    "Compile the protocol buffer, that generates the following files: `match_service_pb2.py` and `match_service_pb2_grpc.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1879a19-d3a4-42ee-9a6a-edf8c32c35d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python -m grpc_tools.protoc -I=. --proto_path=./googleapis --python_out=. --grpc_python_out=. match_service.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce329aa2-50fd-445a-aee0-d5b856a34765",
   "metadata": {},
   "source": [
    "### Obtain Private Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b9b1423-b401-4a9c-a0ba-2d4d06f51605",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.23.0.14'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPLOYED_INDEX_SERVER_IP = (\n",
    "    list(index_endpoint_client.list_index_endpoints(parent=PARENT))[0]\n",
    "    .deployed_indexes[0]\n",
    "    .private_endpoints.match_grpc_address\n",
    ")\n",
    "DEPLOYED_INDEX_SERVER_IP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728b4ba-dc89-436f-b78a-03ac7d663515",
   "metadata": {},
   "source": [
    "### Test the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ec30019-2420-4f56-a044-247903f1aa65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import match_service_pb2\n",
    "import match_service_pb2_grpc\n",
    "\n",
    "channel = grpc.insecure_channel(\"{}:10000\".format(DEPLOYED_INDEX_SERVER_IP))\n",
    "stub = match_service_pb2_grpc.MatchServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d4456bd-cf75-4c37-8349-184485eb56e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test query\n",
    "query = [\n",
    "    -0.11333,\n",
    "    0.48402,\n",
    "    0.090771,\n",
    "    -0.22439,\n",
    "    0.034206,\n",
    "    -0.55831,\n",
    "    0.041849,\n",
    "    -0.53573,\n",
    "    0.18809,\n",
    "    -0.58722,\n",
    "    0.015313,\n",
    "    -0.014555,\n",
    "    0.80842,\n",
    "    -0.038519,\n",
    "    0.75348,\n",
    "    0.70502,\n",
    "    -0.17863,\n",
    "    0.3222,\n",
    "    0.67575,\n",
    "    0.67198,\n",
    "    0.26044,\n",
    "    0.4187,\n",
    "    -0.34122,\n",
    "    0.2286,\n",
    "    -0.53529,\n",
    "    1.2582,\n",
    "    -0.091543,\n",
    "    0.19716,\n",
    "    -0.037454,\n",
    "    -0.3336,\n",
    "    0.31399,\n",
    "    0.36488,\n",
    "    0.71263,\n",
    "    0.1307,\n",
    "    -0.24654,\n",
    "    -0.52445,\n",
    "    -0.036091,\n",
    "    0.55068,\n",
    "    0.10017,\n",
    "    0.48095,\n",
    "    0.71104,\n",
    "    -0.053462,\n",
    "    0.22325,\n",
    "    0.30917,\n",
    "    -0.39926,\n",
    "    0.036634,\n",
    "    -0.35431,\n",
    "    -0.42795,\n",
    "    0.46444,\n",
    "    0.25586,\n",
    "    0.68257,\n",
    "    -0.20821,\n",
    "    0.38433,\n",
    "    0.055773,\n",
    "    -0.2539,\n",
    "    -0.20804,\n",
    "    0.52522,\n",
    "    -0.11399,\n",
    "    -0.3253,\n",
    "    -0.44104,\n",
    "    0.17528,\n",
    "    0.62255,\n",
    "    0.50237,\n",
    "    -0.7607,\n",
    "    -0.071786,\n",
    "    0.0080131,\n",
    "    -0.13286,\n",
    "    0.50097,\n",
    "    0.18824,\n",
    "    -0.54722,\n",
    "    -0.42664,\n",
    "    0.4292,\n",
    "    0.14877,\n",
    "    -0.0072514,\n",
    "    -0.16484,\n",
    "    -0.059798,\n",
    "    0.9895,\n",
    "    -0.61738,\n",
    "    0.054169,\n",
    "    0.48424,\n",
    "    -0.35084,\n",
    "    -0.27053,\n",
    "    0.37829,\n",
    "    0.11503,\n",
    "    -0.39613,\n",
    "    0.24266,\n",
    "    0.39147,\n",
    "    -0.075256,\n",
    "    0.65093,\n",
    "    -0.20822,\n",
    "    -0.17456,\n",
    "    0.53571,\n",
    "    -0.16537,\n",
    "    0.13582,\n",
    "    -0.56016,\n",
    "    0.016964,\n",
    "    0.1277,\n",
    "    0.94071,\n",
    "    -0.22608,\n",
    "    -0.021106,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fd47f99-1c73-4687-ba1b-c7099e36e4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor {\n",
       "  id: \"0\"\n",
       "  distance: 17.592369079589844\n",
       "}\n",
       "neighbor {\n",
       "  id: \"31\"\n",
       "  distance: 14.614908218383789\n",
       "}\n",
       "neighbor {\n",
       "  id: \"50\"\n",
       "  distance: 11.242000579833984\n",
       "}\n",
       "neighbor {\n",
       "  id: \"42\"\n",
       "  distance: 10.925321578979492\n",
       "}\n",
       "neighbor {\n",
       "  id: \"46\"\n",
       "  distance: 10.185911178588867\n",
       "}\n",
       "neighbor {\n",
       "  id: \"100\"\n",
       "  distance: 10.031323432922363\n",
       "}\n",
       "neighbor {\n",
       "  id: \"71\"\n",
       "  distance: 9.4601297378540039\n",
       "}\n",
       "neighbor {\n",
       "  id: \"64\"\n",
       "  distance: 9.3296346664428711\n",
       "}\n",
       "neighbor {\n",
       "  id: \"54\"\n",
       "  distance: 9.25944709777832\n",
       "}\n",
       "neighbor {\n",
       "  id: \"98\"\n",
       "  distance: 8.94312858581543\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = match_service_pb2.MatchRequest()\n",
    "request.deployed_index_id = DEPLOYED_INDEX_ID\n",
    "for val in query:\n",
    "    request.float_val.append(val)\n",
    "\n",
    "# The output before stream update\n",
    "response = stub.Match(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b9bab-ed9e-4cd8-a59a-202202a1ff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d42703f6-bbd3-4447-8040-c2a78e05ad10",
   "metadata": {},
   "source": [
    "## Insert datapoints\n",
    "\n",
    "We add a new embedding in the index, and we verify that it appears in the next request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78c6a9b5-aa11-4095-aa2a-10353f9bddd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor {\n",
       "  id: \"0\"\n",
       "  distance: 17.592369079589844\n",
       "}\n",
       "neighbor {\n",
       "  id: \"101\"\n",
       "  distance: 17.592369079589844\n",
       "}\n",
       "neighbor {\n",
       "  id: \"31\"\n",
       "  distance: 14.614908218383789\n",
       "}\n",
       "neighbor {\n",
       "  id: \"50\"\n",
       "  distance: 11.242000579833984\n",
       "}\n",
       "neighbor {\n",
       "  id: \"42\"\n",
       "  distance: 10.925321578979492\n",
       "}\n",
       "neighbor {\n",
       "  id: \"46\"\n",
       "  distance: 10.185911178588867\n",
       "}\n",
       "neighbor {\n",
       "  id: \"100\"\n",
       "  distance: 10.031323432922363\n",
       "}\n",
       "neighbor {\n",
       "  id: \"71\"\n",
       "  distance: 9.4601297378540039\n",
       "}\n",
       "neighbor {\n",
       "  id: \"64\"\n",
       "  distance: 9.3296346664428711\n",
       "}\n",
       "neighbor {\n",
       "  id: \"54\"\n",
       "  distance: 9.25944709777832\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_datapoints_payload = aiplatform_v1.IndexDatapoint(\n",
    "    datapoint_id=\"101\",\n",
    "    feature_vector=query,\n",
    "    restricts=[{\"namespace\": \"class\", \"allow_list\": [\"101\"]}],\n",
    "    crowding_tag=aiplatform_v1.IndexDatapoint.CrowdingTag(crowding_attribute=\"b\"),\n",
    ")\n",
    "\n",
    "upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "    index=INDEX_RESOURCE_NAME, datapoints=[insert_datapoints_payload]\n",
    ")\n",
    "\n",
    "index_client.upsert_datapoints(request=upsert_request)\n",
    "\n",
    "request = match_service_pb2.MatchRequest()\n",
    "request.deployed_index_id = DEPLOYED_INDEX_ID\n",
    "for val in query:\n",
    "    request.float_val.append(val)\n",
    "\n",
    "# The new inserted datapoint with id 101 will show up in the output\n",
    "response = stub.Match(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1eaba-d718-4aee-be75-a8d17dacfbbe",
   "metadata": {},
   "source": [
    "## Add filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d63f7ef2-5e08-4388-951c-269c204487c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor {\n",
       "  id: \"101\"\n",
       "  distance: 17.592369079589844\n",
       "}\n",
       "neighbor {\n",
       "  id: \"1\"\n",
       "  distance: 2.4347081184387207\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = match_service_pb2.MatchRequest()\n",
    "request.deployed_index_id = DEPLOYED_INDEX_ID\n",
    "for val in query:\n",
    "    request.float_val.append(val)\n",
    "\n",
    "# Only the datapoints whose id is 1 and 101 will show up in the output\n",
    "restrict = match_service_pb2.Namespace()\n",
    "restrict.name = \"class\"\n",
    "restrict.allow_tokens.append(\"1\")\n",
    "restrict.allow_tokens.append(\"101\")\n",
    "\n",
    "request.restricts.append(restrict)\n",
    "\n",
    "response = stub.Match(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda2e59-3317-4669-9abe-5f803bddd9d8",
   "metadata": {},
   "source": [
    "## Update datapoint filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06a7d5e7-6e8d-47b6-be36-13c3483c7979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor {\n",
       "  id: \"1\"\n",
       "  distance: 2.4347081184387207\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_datapoints_payload = aiplatform_v1.IndexDatapoint(\n",
    "    datapoint_id=\"101\",\n",
    "    feature_vector=query,\n",
    "    restricts=[{\"namespace\": \"class\", \"allow_list\": [\"102\"]}],\n",
    "    crowding_tag=aiplatform_v1.IndexDatapoint.CrowdingTag(crowding_attribute=\"b\"),\n",
    ")\n",
    "\n",
    "upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "    index=INDEX_RESOURCE_NAME, datapoints=[update_datapoints_payload]\n",
    ")\n",
    "\n",
    "index_client.upsert_datapoints(request=upsert_request)\n",
    "\n",
    "response = stub.Match(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04cb674-bbdc-4559-a753-4a09e7fec8df",
   "metadata": {},
   "source": [
    "## Add crowding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81236f4c-0b41-411d-8ffe-6421218cda60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor {\n",
       "  id: \"0\"\n",
       "  distance: 17.592369079589844\n",
       "}\n",
       "neighbor {\n",
       "  id: \"101\"\n",
       "  distance: 17.592369079589844\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = match_service_pb2.MatchRequest()\n",
    "request.deployed_index_id = DEPLOYED_INDEX_ID\n",
    "for val in query:\n",
    "    request.float_val.append(val)\n",
    "\n",
    "# Set the limit of the number of neighbors in each crowding to 1\n",
    "# So no more than one neighbor of each crowding group will appear in the output\n",
    "request.per_crowding_attribute_num_neighbors = 1\n",
    "\n",
    "response = stub.Match(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea5e33-dd64-4887-970c-358cbb7f3627",
   "metadata": {},
   "source": [
    "## Update datapoint crowding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fd0e598-7279-4749-87db-07054b616722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor {\n",
       "  id: \"0\"\n",
       "  distance: 17.592369079589844\n",
       "}\n",
       "neighbor {\n",
       "  id: \"31\"\n",
       "  distance: 14.614908218383789\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the crowding_attribute from 'b' to 'a' for the datapoint with id '101' by using stream update\n",
    "update_datapoints_payload = aiplatform_v1.IndexDatapoint(\n",
    "    datapoint_id=\"101\",\n",
    "    feature_vector=query,\n",
    "    restricts=[{\"namespace\": \"class\", \"allow_list\": [\"101\"]}],\n",
    "    crowding_tag=aiplatform_v1.IndexDatapoint.CrowdingTag(crowding_attribute=\"a\"),\n",
    ")\n",
    "\n",
    "upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "    index=INDEX_RESOURCE_NAME, datapoints=[update_datapoints_payload]\n",
    ")\n",
    "\n",
    "index_client.upsert_datapoints(request=upsert_request)\n",
    "\n",
    "response = stub.Match(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895768d-8f44-46b2-8d96-79d052d5cf78",
   "metadata": {},
   "source": [
    "## Remove datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6940ce70-651c-443b-9a05-48842fb60726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor {\n",
       "  id: \"0\"\n",
       "  distance: 17.592369079589844\n",
       "}\n",
       "neighbor {\n",
       "  id: \"31\"\n",
       "  distance: 14.614908218383789\n",
       "}\n",
       "neighbor {\n",
       "  id: \"50\"\n",
       "  distance: 11.242000579833984\n",
       "}\n",
       "neighbor {\n",
       "  id: \"42\"\n",
       "  distance: 10.925321578979492\n",
       "}\n",
       "neighbor {\n",
       "  id: \"46\"\n",
       "  distance: 10.185911178588867\n",
       "}\n",
       "neighbor {\n",
       "  id: \"100\"\n",
       "  distance: 10.031323432922363\n",
       "}\n",
       "neighbor {\n",
       "  id: \"71\"\n",
       "  distance: 9.4601297378540039\n",
       "}\n",
       "neighbor {\n",
       "  id: \"64\"\n",
       "  distance: 9.3296346664428711\n",
       "}\n",
       "neighbor {\n",
       "  id: \"54\"\n",
       "  distance: 9.25944709777832\n",
       "}\n",
       "neighbor {\n",
       "  id: \"98\"\n",
       "  distance: 8.94312858581543\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the datapoint with id '101' from the index\n",
    "remove_request = aiplatform_v1.RemoveDatapointsRequest(\n",
    "    index=INDEX_RESOURCE_NAME, datapoint_ids=[\"101\"]\n",
    ")\n",
    "\n",
    "index_client.remove_datapoints(request=remove_request)\n",
    "\n",
    "request = match_service_pb2.MatchRequest()\n",
    "request.deployed_index_id = DEPLOYED_INDEX_ID\n",
    "for val in query:\n",
    "    request.float_val.append(val)\n",
    "\n",
    "response = stub.Match(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f86f4-e5b7-4a2a-8a14-cb4122700c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
