{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bc8bfa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Index\n",
    "- [Vector Search: Understanding the True Meaning of Queries](#vector-search-understanding-the-true-meaning-of-queries)\n",
    "\n",
    "- [Indexing and Search](#indexing-and-search)\n",
    "    - [Measuring Vector Distance (Similarity Metrics)](#1-measuring-vector-distance-similarity-metrics)\n",
    "    - [Fast and Scalable Vector Search](#2-fast-and-scalable-vector-search)\n",
    "    - [Vertex AI Vector Search (formerly Matching Engine)](#vertex-ai-vector-search-formerly-matching-engine)\n",
    "\n",
    "- [The Problem: AI Hallucination üòµ‚Äçüí´](#the-problem-ai-hallucination-)\n",
    "    - [What Causes AI Hallucinations?](#what-causes-ai-hallucinations)\n",
    "    - [Traditional Solutions and Their Limitations](#traditional-solutions-and-their-limitations)\n",
    "    - [The RAG Solution: An Open-Book Exam for AI üìñ](#the-rag-solution-an-open-book-exam-for-ai-)\n",
    "    - [How RAG Works with Vector Search](#how-rag-works-with-vector-search)\n",
    "\n",
    "- [The Challenge: Beyond Semantic Search ü§î](#the-challenge-beyond-semantic-search-)\n",
    "    - [What is Hybrid Search? ü§ù](#what-is-hybrid-search-)\n",
    "    - [How Hybrid Search Works ‚öôÔ∏è](#how-hybrid-search-works-)\n",
    "    - [Implementation with Vertex AI Vector Search üõ†Ô∏è](#implementation-with-vertex-ai-vector-search-)\n",
    "    - [Example Result](#example-result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae8bbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40f5e88e",
   "metadata": {},
   "source": [
    "# Vector Search: Understanding the True Meaning of Queries\n",
    "\n",
    "## What is Vector Search?\n",
    "\n",
    "Vector Search is a technology that enables search systems to understand the **semantic meaning of queries**, rather than just matching keywords. It focuses on **semantic similarity**, allowing systems to find results that are conceptually related, even if exact terms aren't used.\n",
    "\n",
    "- Traditional **keyword search** excels at matching explicit terms but lacks the ability to understand context or underlying meaning. For example, it might find \"summer tops\" but miss related items like \"swimming suits\" or fail to infer intent, such as \"attire for a beach party.\"\n",
    "\n",
    "- Vector Search (with its focus on semantic search) provides a crucial solution by transforming data into **meaningful embeddings**, enabling a deeper understanding of user intent. \n",
    "\n",
    "## Benefits of Vector Search\n",
    "\n",
    "1.  **Semantic Understanding:**\n",
    "      * Finds results similar in meaning to a query, even without exact keyword matches.\n",
    "      * Highly effective for natural language queries where precise or technical language may not be used.\n",
    "2.  **Multimodal Search Capabilities:**\n",
    "      * Can be applied to various data types, including text, images, and audio.\n",
    "      * Enables applications where users can search using multiple data types (e.g., image search, voice search).\n",
    "3.  **Personalization and Recommendation:**\n",
    "      * Leverages context understanding to personalize search results and recommendations.\n",
    "      * Helps users discover more relevant and interesting information.\n",
    "4.  **Generative AI Integration:**\n",
    "      * A critical component in generative AI applications for fast and efficient information retrieval.\n",
    "      * Becoming a foundational element in AI and machine learning services.\n",
    "\n",
    "Vector Search is transforming how people engage with information, leading to more relevant, efficient, and personalized search experiences as data volumes and user expectations grow.\n",
    "\n",
    "## How Vector Search Works\n",
    "\n",
    "Vector Search involves a three-step process:\n",
    "\n",
    "![](docs/images/vector-search-steps.png)\n",
    "\n",
    "1.  **Encode Data into Vectors:** AI models, known as **Embedding Models**, convert various data types (text, images, audio) into numerical representations called **vectors**. These vectors capture the semantic meaning of the data.\n",
    "2.  **Create an Index:** An index is built from these vectors to enable fast and scalable search across billions of items.\n",
    "3.  **Search the Vector Space:** When a query is made, it is also encoded into a vector. This query vector is then used to efficiently search the indexed vector space for other vectors (data items) that are semantically similar.\n",
    "\n",
    "### Detailed View: Development vs. Serving\n",
    "\n",
    "  * **At Development Time (Building the System):**\n",
    "      * Generate embeddings for all data.\n",
    "      * Build and deploy the vector index.\n",
    "  * **At Serving Time (Responding to Queries):**\n",
    "      * Encode the user's query into a vector.\n",
    "      * Search the vector space using the query vector.\n",
    "      * Serve the most relevant results.\n",
    "\n",
    "## Core Challenges\n",
    "\n",
    "To implement Vector Search, two major challenges must be addressed:\n",
    "\n",
    "1.  **How to Encode Data:** Converting diverse, multimodal data into representations that accurately capture semantic meanings. (Answer: **Embeddings**)\n",
    "2.  **How to Index and Search Data:** Building an efficient search space that enables fast and scalable lookups. (Answer: **Vector Search Indexing**)\n",
    "\n",
    "-----\n",
    "\n",
    "## Further Reading & Resources\n",
    "\n",
    "To deepen your understanding of Vector Search, Embeddings, and related technologies, explore these resources:\n",
    "\n",
    "### General Concepts & Explanations:\n",
    "\n",
    "  * **Google Cloud Blog - What is Vector Search?**\n",
    "      * A good starting point for understanding the fundamentals and applications.\n",
    "      * [Link to a Google Cloud \"What is Vector Search\" article](https://www.google.com/search?q=https://cloud.google.com/learn/what-is-vector-search) (You can search for the most recent official one)\n",
    "  * **Pinecone Blog - What is Vector Search?**\n",
    "      * Pinecone is a dedicated vector database company, and their blog often has excellent, in-depth explanations.\n",
    "      * [Link to a Pinecone \"What is Vector Search\" article](https://www.google.com/search?q=https://www.pinecone.io/learn/vector-search/)\n",
    "\n",
    "### Vector Databases & Open-Source Frameworks:\n",
    "\n",
    "These are specialized databases and libraries designed to store and query vectors efficiently.\n",
    "\n",
    "  * **Pinecone:**\n",
    "      * A popular managed vector database service.\n",
    "      * [Website: pinecone.io](https://www.pinecone.io/)\n",
    "  * **Weaviate:**\n",
    "      * An open-source vector database that also includes built-in search capabilities.\n",
    "      * [Website: weaviate.io](https://weaviate.io/)\n",
    "      * [GitHub: Weaviate](https://github.com/weaviate/weaviate)\n",
    "  * **Qdrant:**\n",
    "      * Another open-source vector similarity search engine.\n",
    "      * [Website: qdrant.tech](https://qdrant.tech/)\n",
    "      * [GitHub: Qdrant](https://github.com/qdrant/qdrant)\n",
    "  * **Faiss (Facebook AI Similarity Search):**\n",
    "      * A library for efficient similarity search and clustering of dense vectors. It's not a database, but a powerful library often used as a backend for vector search systems.\n",
    "      * [GitHub: Faiss](https://github.com/facebookresearch/faiss)\n",
    "  * **Chroma:**\n",
    "      * An open-source embedding database for building AI applications.\n",
    "      * [Website: trychroma.com](https://www.trychroma.com/)\n",
    "      * [GitHub: Chroma](https://github.com/chroma-core/chroma)\n",
    "  * **Elasticsearch (with Vector Search capabilities):**\n",
    "      * While primarily a full-text search engine, recent versions of Elasticsearch (and OpenSearch) have added native vector search capabilities.\n",
    "      * [Elasticsearch Vector Search documentation](https://www.elastic.co/what-is/vector-search)\n",
    "\n",
    "### Embeddings & Models:\n",
    "\n",
    "  * **Hugging Face Hub (Models):**\n",
    "      * A vast repository of pre-trained models, including many for generating embeddings (e.g., Sentence-BERT, OpenAI's embedding models).\n",
    "      * [Website: huggingface.co/models](https://huggingface.co/models)\n",
    "  * **OpenAI Embeddings:**\n",
    "      * OpenAI offers powerful embedding models accessible via API, widely used for various semantic tasks.\n",
    "      * [OpenAI Embeddings Documentation](https://platform.openai.com/docs/guides/embeddings)\n",
    "  * **Google's Universal Sentence Encoder:**\n",
    "      * A model for encoding text into high-dimensional vectors.\n",
    "      * [TensorFlow Hub: Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78a1de4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5cb990",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Indexing and Search\n",
    "\n",
    "Following the generation of embeddings (covered previously), the next critical steps in Vector Search are **indexing** and **searching** these vector spaces efficiently. This involves addressing two primary challenges:\n",
    "\n",
    "1.  How to measure the distance (similarity) between vectors (see *Similarity Metrics* into [00a-docs-theory-on-embeddings.ipynb](00a-docs-theory-on-embeddings.ipynb)).\n",
    "2.  How to search vectors in a fast and scalable way.\n",
    "\n",
    "\n",
    "## 2\\. Fast and Scalable Vector Search\n",
    "\n",
    "Once distances can be measured, the challenge shifts to finding similar vectors efficiently within potentially vast vector spaces (millions to billions of embeddings).\n",
    "\n",
    "### Search Algorithms:\n",
    "\n",
    "1.  **Brute Force Algorithm:**\n",
    "\n",
    "      * **Process:**\n",
    "          1.  Calculate distances from the query vector to *all* other vectors in the space.\n",
    "          2.  Sort all distances.\n",
    "          3.  Find the top `k` nearest vectors.\n",
    "      * **Complexity:** `O(N*d)` where `N` is the number of vectors and `d` is the number of dimensions.\n",
    "      * **Drawback:** Impractical and computationally bottlenecked for large datasets (`N` in the millions/billions).\n",
    "\n",
    "2.  **Approximate Nearest Neighbor (ANN) Algorithms:**\n",
    "\n",
    "      * **Concept:** Accelerate search by trading a small amount of accuracy for significant speed improvements. They avoid exhaustive search by intelligently pruning the search space.\n",
    "      * **How it works (general idea):** Divides the search space into smaller partitions, indexes them using data structures (like trees or hashes), and then searches only the most relevant partitions.\n",
    "      * **Example (TreeAh - shallow tree and asymmetric hashing):** A production-ready algorithm that uses tree structures for indexing.\n",
    "\n",
    "### ScaNN: Scalable Approximate Nearest Neighbor\n",
    "\n",
    "In 2020, Google Research introduced **ScaNN** (Scalable Approximate Nearest Neighbor), a leading ANN algorithm powering services like Google Search and YouTube's recommendation system. \n",
    "\n",
    "ScaNN achieves fast and scalable vector search by combining:\n",
    "\n",
    "1.  **Reduced Search Space (Space Pruning):**\n",
    "      * **Multilevel Tree Search:** The vector space is divided into hierarchical partitions. A search tree represents this structure, with nodes as centroids of partitions.\n",
    "      * **Pruning:** During a query, the tree is traversed (from root to branches to leaves), and irrelevant partitions are pruned, focusing the search on the most relevant sub-partitions.\n",
    "2.  **Compressed Vector Size (Data Quantization):**\n",
    "      * **Technique:** Compresses data points to save space and reduce indexing time (e.g., reducing a 9-dimensional vector from 9 floats to 12 bits).\n",
    "3.  **Increased Ranking Efficiency (Business Logic Integration):**\n",
    "      * **Filtering:** Incorporates business logic to filter results based on specific criteria (e.g., \"resorts in the United States,\" \"red dresses\") *before* or *during* similarity ranking, restricting the search to a relevant subset of the dataset.\n",
    "\n",
    "## Vertex AI Vector Search (formerly Matching Engine)\n",
    "\n",
    "Vertex AI Vector Search is a fully managed similarity vector search service provided by Google Cloud.\n",
    "\n",
    "  * **Foundation:** Utilizes an advanced version of the ScaNN algorithm.\n",
    "  * **Benefits:** Offers fast searching, low latencies, and scalability to billions of vectors, often at a lower cost compared to similar services.\n",
    "\n",
    "-----\n",
    "\n",
    "## Further Reading & Resources\n",
    "\n",
    "### Approximate Nearest Neighbor (ANN) Algorithms & Vector Databases:\n",
    "\n",
    "  * **ScaNN: Efficient Vector Similarity Search (Google AI Blog):**\n",
    "      * The official announcement and explanation of ScaNN.\n",
    "      * [Link: ScaNN: Efficient Vector Similarity Search](https://www.google.com/search?q=https://ai.googleblog.com/2020/07/scann-efficient-vector-similarity-search.html)\n",
    "  * **The Missing Piece: An Introduction to Approximate Nearest Neighbor (ANN) Search (Pinecone Blog):**\n",
    "      * A good overview of ANN concepts.\n",
    "      * [Link: Introduction to ANN Search](https://www.google.com/search?q=https://www.pinecone.io/learn/approximate-nearest-neighbor/)\n",
    "  * **Faiss (Facebook AI Similarity Search):**\n",
    "      * An open-source library for efficient similarity search. Essential for understanding ANN implementations.\n",
    "      * [GitHub: Faiss](https://github.com/facebookresearch/faiss)\n",
    "  * **HNSW (Hierarchical Navigable Small Worlds):**\n",
    "      * A popular graph-based ANN algorithm widely used in vector databases.\n",
    "      * [Paper: Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs](https://arxiv.org/abs/1603.09320)\n",
    "  * **Vertex AI Vector Search Documentation:**\n",
    "      * Official Google Cloud documentation for their managed vector search service.\n",
    "      * [Link: Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/matching-engine/overview) (Look for the most current link for \"Vector Search\" if \"Matching Engine\" is outdated)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75472c8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "939698f0",
   "metadata": {},
   "source": [
    "## The Problem: AI Hallucination üòµ‚Äçüí´\n",
    "\n",
    "A significant challenge with AI models like chatbots is **hallucination**, a situation where the AI confidently delivers a completely inaccurate response. This occurs because Large Language Models (LLMs) have an understanding limited to their training data, which can become outdated or lack specific organizational knowledge. This \"grounding problem\" undermines user trust in AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "### What Causes AI Hallucinations?\n",
    "\n",
    "LLMs are prone to hallucination for several key reasons:\n",
    "\n",
    "* **Limited Knowledge:** Their understanding is confined to their training data. They lack awareness of your company's internal data, specific industry knowledge, or real-time information.\n",
    "* **Inability to Verify:** They cannot check the accuracy of their own training data.\n",
    "* **Lack of Context:** They often assume user prompts are factually correct and are unable to ask for clarifying information.\n",
    "\n",
    "---\n",
    "\n",
    "### Traditional Solutions and Their Limitations\n",
    "\n",
    "Several methods have been used to combat hallucinations, but each has drawbacks:\n",
    "\n",
    "* **Fine-tuning:** This involves retraining an LLM with new, specific data. While effective, it is often costly and requires extensive data and computational resources.\n",
    "* **Human Review:** Having humans verify AI responses increases accuracy but is expensive, time-consuming, and not always scalable enough to catch every error.\n",
    "* **Prompt Engineering:** Carefully crafting prompts can help steer the AI toward more accurate answers, but its effectiveness is limited, especially at scale.\n",
    "\n",
    "---\n",
    "\n",
    "## The RAG Solution: An Open-Book Exam for AI üìñ\n",
    "\n",
    "A more effective solution is **Retrieval-Augmented Generation (RAG)**. RAG is an architecture that combines the strengths of retrieval technology (like Vector Search) and generative AI models (like LLMs).\n",
    "\n",
    "* **Retrieval Models (Vector Search):** Excellent at finding specific, factual information from a large set of documents.\n",
    "* **Generative Models (LLMs):** Excellent at generating coherent, fluent, and creative text.\n",
    "\n",
    "RAG bridges the gap between these two. It effectively gives the LLM an **\"open-book exam,\"** allowing it to look up information from an external, up-to-date knowledge base *before* generating an answer. This grounds the AI's response in verifiable facts, reducing the likelihood of hallucination.\n",
    "\n",
    "---\n",
    "\n",
    "### How RAG Works with Vector Search\n",
    "\n",
    "**Vector Search** is the key technology that powers the retrieval function in a RAG system. The process works as follows:\n",
    "\n",
    "1.  **Encode and Index:** New, trustworthy information (e.g., company policies, product docs, real-time alerts) is encoded into vector embeddings and stored in a vector database for efficient searching.\n",
    "2.  **Query:** A user's question is also converted into a vector embedding.\n",
    "3.  **Search and Retrieve:** The system uses Vector Search to find the most semantically similar and relevant documents from the vector database based on the user's query embedding.\n",
    "4.  **Augment and Generate:** The original question, along with the retrieved factual information, is passed to the LLM.\n",
    "5.  **Grounded Response:** The LLM then generates a final answer that incorporates the fresh, verified information, resulting in a more reliable and trustworthy response.\n",
    "\n",
    "\n",
    "![](docs/images/rag-pipeline.png)\n",
    "\n",
    "\n",
    "This creates a **grounded agent**‚Äîan AI that can perform fact-checks against a trusted source of information.\n",
    "\n",
    "---\n",
    "\n",
    "## The Next Step: Hybrid Search\n",
    "\n",
    "While semantic search is powerful for understanding context, it can sometimes struggle with retrieving specific, exact terms (like a new product SKU) that weren't in its original training data. To address this, the next evolution is **hybrid search**, which integrates the contextual understanding of semantic search with the precision of traditional keyword search to significantly enhance retrieval performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e759e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## The Challenge: Beyond Semantic Search ü§î\n",
    "\n",
    "While **semantic search** is excellent at understanding the meaning and context of words, it can struggle with **out-of-domain information**‚Äîdata the embedding model hasn't been trained on, such as a brand-new product name or a specific barcode. This is where **Hybrid Search** comes in.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Hybrid Search? ü§ù\n",
    "\n",
    "**Hybrid Search** combines the strengths of two search methods to achieve a more comprehensive and precise search experience:\n",
    "\n",
    "* **Semantic Search:** Handles nuanced, contextual queries by understanding meaning.\n",
    "* **Keyword Search:** Accurately captures specific, literal terms, especially those that are out-of-domain.\n",
    "\n",
    "By merging these two, you get the best of both worlds. A well-known example is **Google Search**, which integrated semantic search with its existing keyword algorithms to significantly improve search quality.\n",
    "\n",
    "### The Old Way vs. The New Way\n",
    "\n",
    "Previously, building a hybrid search engine was a difficult task, requiring the maintenance of two separate engines and a complex process to merge and re-rank their results. Modern platforms like **Vertex AI Vector Search** have simplified this process, allowing for the creation of a single, powerful search system.\n",
    "\n",
    "---\n",
    "\n",
    "## How Hybrid Search Works ‚öôÔ∏è\n",
    "\n",
    "Hybrid search follows the familiar `encode -> index -> search` process, but it runs two parallel tracks that are later combined.\n",
    "\n",
    "### 1. The Keyword Search Track (Token-based)\n",
    "\n",
    "This track focuses on matching exact words or tokens.\n",
    "\n",
    "* **Encoding (Creating Sparse Embeddings):**\n",
    "    * Text is broken into tokens (words or sub-words).\n",
    "    * Instead of simple one-hot encoding, this method often uses a weighting algorithm like **TF-IDF (Term Frequency-Inverse Document Frequency)**.\n",
    "    * TF-IDF assesses a word's importance within a document relative to a whole collection of documents, emphasizing significant terms.\n",
    "    * The result is a high-dimensional vector with mostly zero values, known as a **sparse embedding**.\n",
    "\n",
    "* **Indexing & Searching:**\n",
    "    * A vector space is created to organize these sparse embeddings. Texts with similar keyword distributions are placed near each other, enabling efficient keyword matching.\n",
    "\n",
    "### 2. The Semantic Search Track\n",
    "\n",
    "This track runs in parallel and focuses on meaning.\n",
    "\n",
    "* **Encoding (Creating Dense Embeddings):**\n",
    "    * As covered previously, an embedding model (like those available through the Vertex AI Embeddings API) converts text into a low-dimensional, meaningful vector called a **dense embedding**.\n",
    "\n",
    "### 3. Combining and Re-ranking the Results\n",
    "\n",
    "This is the final, crucial step where the results from both tracks are merged.\n",
    "\n",
    "* **Reciprocal Rank Fusion (RRF):**\n",
    "    * Instead of just mixing the two result lists, RRF is a sophisticated method that intelligently combines them.\n",
    "    * It elevates items that rank highly in *any* of the individual lists.\n",
    "    * An item that ranks very high in just one list (e.g., a perfect keyword match) or ranks consistently well across both lists will be prioritized in the final results.\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation with Vertex AI Vector Search üõ†Ô∏è\n",
    "\n",
    "Modern APIs abstract away much of the complexity, making implementation straightforward.\n",
    "\n",
    "1.  **Generate Embeddings:**\n",
    "    * **Sparse Embeddings:** Use a vectorizer library (like `scikit-learn`'s TF-IDF vectorizer) to convert your text data into sparse embeddings for keyword search.\n",
    "    * **Dense Embeddings:** Use a service like the Vertex AI Embeddings API to generate dense embeddings for semantic search.\n",
    "\n",
    "2.  **Store and Index:**\n",
    "    * Combine both the dense and sparse embeddings for each data point into a single record (e.g., in a JSON file).\n",
    "    * Use this file to create a single hybrid vector index in Vertex AI Vector Search.\n",
    "\n",
    "3.  **Query the Index:**\n",
    "    * When performing a search, create a **hybrid query object** that contains both the sparse embedding (for keywords) and the dense embedding (for semantics) of your search query.\n",
    "    * The system executes the query, leveraging both embedding types and using RRF to fuse the results.\n",
    "\n",
    "### Example Result\n",
    "\n",
    "A hybrid search for \"kids sunglasses\" might return:\n",
    "\n",
    "* **Top Result:** \"Google Blue Kids Sunglasses\" (high similarity for both dense and sparse embeddings).\n",
    "* **Middle Result:** \"Google White Classic Youth Tee\" (lower rank because it doesn't contain the keyword \"kids,\" but \"youth tee\" is semantically similar enough to be included).\n",
    "\n",
    "This demonstrates how hybrid search enables the rapid finding of similar items based on both literal keywords and conceptual meaning."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
